### 단일서버의 사용자 요청 처리 흐름

- 단일서버란?
    - 웹, 앱, 데이터베이스, 캐시 등이 서버 한대에서 실행되는 것
1. 사용자는 도메인 이름을 이용하여 웹사이트에 접속
2. 도메인 이름을 도메인 이름 서비스에 질의하여 IP 주소로 변환
3. DNS 조회 결과로 IP 주소로 반환
4. 해당 IP 주소로 HTTP 요청이 전달
5. 요청을 받은 웹 서버는 HTML 페이지나 JSON 형태의 응답을 반환
- 웹 애플리케이션
    - 비지니스 로직, 데이터 저장 등을 처리하기 위해서는 서버 구현용 언어를 사용하고, 프레젠테이션 용으로는 클라이언트 구현용 언어를 사용함
- 모바일 앱
    - 모바일 앱과 웹 서버 통신을 위해서는 HTTP 프로토콜 이용

### 데이터베이스

- 데이터베이스용 서버를 하나 추가
- 관계형 데이터베이스
    - MySQL, PostgreSQL 등
    - 관계형 데이터베이스는 자료를 테이블과 열, 칼럼으로 표현
    - SQL을 사용하면 여러 테이블에 있는 데이터를 그 관계에 따라 조인하여 합칠 수 있음
- 비 관계형 데이터베이스
    - CouchDB, Neo4j
    - 키 값 저장소
    - 그래프 저장소
    - 칼럼 저장소
    - 문서 저장소
    - NoSQL이 적합한 경우
        - 아주 낮은 응답지연시간이 요구되는 경우
        - 다루는 데이터가 비정형인 경우
        - 데이터를 직렬화하거나 역직렬화 할 수 있기만 하면되는 경우
        - 아주 많은 데이터를 저장할 필요가 없는 경우

### 수직적 규모 확장 VS 수평적 규모 확장

- 수직적 규모 확장(=스케일 업) : 서버에 고사양 자원을 추가하는 행위
- 수평적 규모 확장(=스케일 아웃) : 더 많은 서버를 추가하여 성능을 개선하는 행위
- 서버로 유입되는 트래픽 양이 적은 경우는 수직적 확장이 좋은 선택
    - 단점
        1. 한계가 있음. 한 대의 서버에 CPU나 메모리를 무한대로 증설할 방법은 없음
        2. 장애에 대한 자동복구 방안이나 다중화 방안을 제시하지 않음. 서버에 장애가 발생하면 웹사이트/앱은 완전히 중단

→ 대규모 애플리케이션을 지원하는 데는 수평적 규모 확장 법이 적절함

### 로드밸런서

- 부하 분산 집합에 속한 웹 서버들에게 트래픽 부하를 고르게 분산하는 역할
1. 로드밸런서의 공개 IP 주소로 접속함
2. 서버 간 통신은 사설 IP 주소를 이용함. (로드 밸런서는 웹 서버와 통신하기 위해 이 주소를 이용)

### 데이터베이스 다중화

- 서버 사이에 주-부 관계를 설정하고 데이터 원본은 주서버에 사본은 부 서버에 저장하는 방식
- 쓰기 연산은 마스터에서만 지원
- 부 데이터베이스는 주 데이터베이스로부터 사본을 전달받으며 읽기 연산만을 지원
- 주 데이터베이스 수 < 부 데이터베이스 수 → 읽기 연산의 비중이 쓰기 연산보다 훨씬 높기 때문
- 데이터베이스 다중화의 장점
    - 주-부 다중화 모델에서 모든 데이터 변경은 주 데이터베이스 서버로만 전달되는 반면 읽기 연산은 부 데이터베이스 서버로 분산된다. 병렬로 처리될 수 있는 쿼리의 수가 늘어나므로, 성능이 좋아짐
    - 안정성 : 데이터베이스 서버 가운데 일부가 파게되어도 데이터는 보존될 것. 데이터를 지역적으로 멀리 떨어진 여러 장소에 다중화 시켜놓을 수 있기 때문
    - 가용성 : 데이터를 여러 지역에 복제해 둠으로써, 하나의 데이터베이스 서버에 장애가 발생하더라도 다른 서버에 있는 데이터를 가져와 계속 서비스 할 수 있게 됨
- 데이터베이스 서버 가운데 하나가 다운되면 무슨일이 벌어지는가?
    - 부 서버가 한 대 뿐인데 다운된 경우 → 읽기 연산은 모두 주 데이터베이스로 전달되며 즉시 새로운 부 데이터베이스 서버가 장애 서버를 대체
    - 부 서버가 여러 대인 경우 → 읽기 연산은 나머지 부 데이터베이스 서버들로 분산될 것이며, 새로운 부 데이터베이스 서버가 장애 서버를 대체
    - 부 서버가 한 대 뿐인데 주 서버가 다운된 경우 → 해당 부 서버가 새로운 주 서버가 되며 새로운 부서버가 추가됨. 이 때, 없는 데이터는 복구 스트립트를 돌려서 추가함. 다중 마스터나 원형 다중화 방식을 도입하면 도움이 될 수 있음

### 로드밸런서 + 데이터 다중화를 고려한 서버 설계안

1. 사용자는 DNS로부터 로드밸런서의 공개 IP 주소를 받음
2. 사용자는 해당 IP를 이용해 로드밸런서에 접속
3. HTTP요청은 서버 1이나 서버2로 전달
4. 웹 서버는 사용자의 데이터를 부 데이터베이스 서버에서 읽음
5. 웹 서버는 데이터 변경 연산 → 주 데이터베이스로 전달

### 캐시

- 값비싼 연산 결과 또는 자주 참조되는 데이터를 메모리 안에 두고, 뒤이은 요청이 보다 빨리 처리될 수 있도록 하는 저장소
- 캐시 계층은 데이터가 잠시 보관되는 곳으로 데이터베이스보다 훨씬 빠름
- 캐시는 어떤 상황에 바람직한가?
    - 데이터 갱신은 자주 일어나지 않지만 참조는 빈번하게 일어나는 경우
- 어떤 데이터를 캐시에 두어야 하는가?
    - 휘발성 메모리에 두므로, 영구적으로 보관활 데이터를 캐시에 두는 것은 바람직하지 않음
- 캐시 데이터는 어떻게 만료되는가? → 적당한 만료 정책 필요
    - 만료 기한은 짧으면 데이터베이스를 너무 자주 읽게되고, 너무 길면 원본과 차이가 날 가능성이 높아짐
    - 따라서 적절한 캐시 만료 정책을 세워야함
- 일관성은 어떻게 유지?
    - 페이스 북에서 내놓은 논문 참고
- 장애 대처 방법
    - 캐시 서버를 한대만 두는 경우 단일 장애지점(SPOF)가 될 수 있음
    - SPOF를 피하기 위해 여러 지역에 걸쳐 캐시 서버를 분산시켜야함
- 캐시 메모리 크기?
    - 캐시 메모리가 너무 작으면 캐시 성능이 떨어짐. 그래서 캐시 메모리를 과할당해서 해결하는 것도 한 가지 방법
- 데이터 방출 정책?
    - LRU, LFU, FIFO 등을 사용하며 경우에 맞게 적용함

### CDN

- CDN은 정적 콘텐츠를 전송하는데 쓰이는 지리적으로 분산된 서버의 네트워크
- 이미지, 비디오, CSS, JS 파일등을 캐시함
- CDN 사용시 고려사항
    - 비용 : 보통 제3사업자에 의해 운영되기 때문에 자주 사용되지 않는 콘텐츠는 캐싱하지 않도록 하기
    - 만료 시한 : 시의성이 중요한 콘텐츠의 경우 만료 시점을 잘 설정해야함. 너무 길면 신선도가 떨어지고, 너무 짧으면 원본 서버에 빈번히 접속하게되어서 좋지 않음
    - 장애 대응 방법 : CDN이 응답하지 않을 경우, 원본 서버로부터 직접 콘텐츠를 가져오도록 클라이언트를 구성해야할 필요가 있음
    - 콘텐츠 무효화 방법
        - CND 서비스 사업자가 제공하는 API를 이용해서 무효화
        - 콘텐츠의 다른 버전을 오브젝트 버저닝 이용

### 무상태 웹 계층

- 상태 정보를 웹 계층에서 제거함
- 상태 정보를 관계형 데이터베이스나 NoSQL과 같은 지속성 저장소에 보관하고, 필요할 때 가져오도록 하는 것

→ 이렇게 구성된 웹 계층을 무상태 웹계층이라고함

- 웹 서버는 상태 정보가 필요한 경우 공유 저장소로부터 데이터를 가져옴

### 데이터센터

- 전세계 어디에서도 쾌적하게 이용할 수 있도록 하기 위함
- 장애가 없는 상황에서 사용자는 가장 가까운 데이터 센터로 안내됨 → 지리적 라우팅이라고 부름
- geoDNS는 사용자의 위치에 따라 도메인 이름을 어떤 IP 주소로 변환할지 결정해주는 DNS 서비스

### 메시지 큐

- 메시지의 무손실을 보장하는 비동기 통신을 지원하는 컴포넌트
- 메시지의 버퍼 역할을 하며, 비동기적으로 전송
- 생산자 또는 발행자라고 불리는 입력 서비스가 메시지를 만들어 메시지큐에 발행
- 큐에는 소비자 혹은 구독자라 불리는 서비스 혹은 서버가 연결되어 있으며, 메시지를 받아 그에 맞는 동작을 수행하는 역할을 함
- 생산자는 소비자 프로세스가 다운되어 있어도 메시지를 발행할 수 있고, 소비자는 생산자 서비스가 가용한 상태가 아니더라도 메시지를 수신할 수 있음

### 로그, 메트릭 그리고 자동화

- 로그
    - 시스템의 오류와 문제들을 보다 쉽게 찾아낼 수 있도록 하기 때문에 에러 로그를 모니터링 하는 것은 중요
- 메트릭
    - 호스트 단위 메트릭 : CPU, 메모리, 디스크 I/O에 관한 메트릭
    - 종합 메트릭 : 데이터베이스 계층의 성능, 캐시 계층의 성능
    - 핵심 비지니스 메트릭 : 일별 능동 사용자, 수익, 재방문
- 자동화
    - 지속적 통합을 도와주는 도구를 활용하면 검증 절차를 자동으로 거치도록 할 수 있어 문제를 쉽게 감지할 수 있음
    - 빌드, 테스트, 배포 절차를 자동화 할 수 있어 개발 생산성을 크게 향상시킬 수 있음

### 데이터베이스의 규모 확장

1. 수직적 확장(=스케일업)
    - 기존 서버에 더 많은 또는 고성능의 자원을 증설하는 방법
    - 약점
        - DB 서버 하드웨어에는 한계가 있으므로 무한 증설 하지 못함
        - SPOF로 인한 위험성이 큼
        - 비용이 많이 듦
2. 수평적 확장(=샤딩)
    - 대규모 데이터베이스를 샤드라고 부르는 작은 단위로 분할하는 기술
    - 모든 샤드는 같은 스키마를 쓰지만 샤드에 보관되는 데이터 사이에는 중복이 없음
    - 샤딩 키(=파티션 키)
    - 샤딩을 도입할 경우 생기는 문제
        1. 데이터 의 재 샤딩
            - 데이터가 너무 많아져서 하나의 샤드로는 감당하기 어려운 경우, 데이터 분포가 불균등하여 공간소모가 다른 샤드에 비해 빨리 진행될 때 필요
        2. 유명인사 문제
            - 특정 샤드에 질의가 집중되어 서버에 과부화가 걸림
        3. 조인과 비정규화
            - 하나의 데이터베이스를 여러 샤드 서버로 쪼개고 나면, 여러 샤드에 걸친 데이터를 조인하기가 힘들어짐
    
    ---
    
    ### 처리율 제한 장치
    
    - 클라이언트 또는 서비스가 보내는 트리팩의 처리율을 제어하기 위한 장치
    - API에 처리율 제한 장치를 두면 좋은 점
        - Dos 공격에 의한 자원 고갈 방지할 수 있음
        - 비용 절감 : 서버를 많이 두지 않아도 되고, 우선순위가 높은 API에 더 많은 자원을 할당할 수 있음
        - 서버 과부화 막을 수 있음
    - 처리율 제한 장치의 위치
        - 클라이언트 : 클라이언트 요청은 쉽게 위변조가 가능하기 때문에 안정적으로 걸 수 없음
        - 서버
            - 미들웨어를 만들어 미들웨어로 하여금 API로 가는 요청을 통제함
            - MSA에서는 보통 API 게이트웨이라고 불리는 컴포넌트에 구현됨
    - API 게이트웨이
        - 처리율 제한, SSL 종단, 사용자 인증, IP 허용 목록 관리 등을 지원하는 완전 위탁관리형 서비스임
    
    ### 처리율 제한 알고리즘
    
    1. 토큰 버킷 알고리즘
        - 토큰 버킷은 사전 설정된 양의 토큰이 주기적으로 채워짐
        - 토큰이 꽉 찬 버킷에는 더 이상의 토큰이 채워지지 않음
        - 요청이 처리될 때마다 토큰을 사용하여
            - 충분한 토큰이 있는 경우 버킷에서 토큰 하나를 꺼낸 뒤 요청을 시스템에 전달
            - 충분한 토큰이 없는 경우 해당 요청은 버려짐
        - 인자
            - 버킷 크기 : 버킷에 담을 수 있는 토큰의 최대 개수
            - 토큰 공급률 : 초당 몇 개의 토큰이 버킷에 공급되는가
        - 장점
            - 구현이 쉬움
            - 메모리 사용 측면에서 효율적
            - 짧은 시간에 집중되는 트래픽도 처리 가능
        - 단점
            - 버킷 크기와 초큰 공급률의 값을 적절하게 튜닝하는 것이 어려움
    2. 누출 버킷 알고리즘
        - 요청이 도착하면 큐가 가득차 있는지 확인후 빈자리가 있는 경우 큐에 요청 추가
        - 큐가 가득차 있는 경우는 새 요청은 버림
        - 지정된 시간마다 큐에서 요청을 꺼내어 처리함
        - 인자
            - 버킷 크기 : 큐의 사이즈와 같은 값
            - 처리율 : 지정된 시간 당 몇 개의 항목을 처리할지 지정하는 값
        - 장점
            - 큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적
            - 고정된 처리율을 갖고 있기 때문에 안정적 출력이 필요한 경우 적합
        - 단점
            - 단시간에 많은 트래픽이 몰리게 되는 경우 오래된 요청이 큐에 쌓이고 요청들을 제때 처리하지 못하면 최신 요청은 버려지게됨
            - 두 개의 인자를 튜닝하기 어려움
    3. 고정 윈도 카운터
        - 타임라인을 고정된 간격의 윈도로 나누고 각 윈도마다 카운터를 붙임
        - 요청이 접수 될때마다 카운터의 값은 1씩 증가
        - 이 값이 사전에 설정된 임계치에 도달하면 새로운 요청은 새 윈도가 열릴때까지 버려짐
        - 장점
            - 메모리 효율이 좋음
            - 이해하기 쉬움
            - 윈도가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기 적합함
        - 단점
            - 윈도 경계 부근에서 일시적으로 많은 트래픽이 몰려드는 경우, 기대했던 시스템의 처리 한도보다 더 많은 양의 요청을 처리하게됨
    4. 이동 윈도 로그
        - 요청의 타임스탬프를 추적함(타임스탬프 데이터는 레디스의 정렬집합 같은 캐시에 보관)
        - 새 요청이 오면 만료된 타임스탬프는 제거
        - 새 요청의 타임스탬프를 로그에 추가
        - 로그의 크기가 허용치보다 같거나 작으면 시스템에 전달, 그렇지 않은 경우는 거부
        - 장점
            - 어느순간의 윈도를 보더라도, 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 않음
        - 단점
            - 다량의 메모리를 사용함(거부된 요청의 타임스탬프도 보관하기 떄문)
    5. 이동 윈도 카운터
        - 고정 윈도 카운터 알고리즘 + 이중 윈도 로깅 알고리즘 결합
        - 현재 1분간의 요청수 + 직전 1분간의 요청수 X 이동 윈도와 직전 1분이 겹치는 비율
        - 장점
            - 짧은 시간에 몰리는 트래픽에도 잘 대응
            - 메모리 효율이 좋음
        - 단점
            - 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하기 떄문에 다소 느슨함

### 처리율 제한 장치 구현

- 레디스와 같은 메모리 기반 저장 장치를 이용하여 구현
- 명령어
    - `INCR`: 메모리에 지정된 카운터 값을 1만큼 증가
    - `EXPIRE`: 카운터에 타임아웃 값을 설정

### **처리율 한도 초과 트래픽의 처리**

- 처리율 제한에 걸리는지 확인하려면 HTTP헤더를 봐야함.
- 처리율 제한장치는 HTTP 응답 헤더를 클라이언트에게 전송하게 됨
    - `X-Ratelimit-Remaining`: 윈도우 내에 남은 처리 가능한 요청의 개수
    - `X-Ratelimit-Limit`: 매 윈도우마다 클라이언트가 전송할 수 있는 요청의 개수
    - `X-Ratelimit-Retry-After`: 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림

### **분산 환경에서의 처리율 제한 장치의 구현**

- 분산 환경에서 처리율 제한 장치를 구현하려면 다음과 같은 두 가지 문제를 해결해야함
1. 경쟁조건
    - 요청을 처리하는 스레드가 각각 병렬로 counter 값을 읽고, 그 중 어느쪽도 아직 변경된 값을 저장하지 않은 상태면 카운터 값이 올바르게 변경되지 않을 수 있음
    
    → 경쟁 조건을 해결하는 가장 널리 알려진 해결책은 락을 거는 것. 락은 시스템의 성능을 떨어뜨릴 수 있음
    
2. 동기화 이슈
    - 처리율 제한 장치 서버를 여러 대 두면 동기화가 필요해짐
    - 웹 계층은 무상태이므로 클라이언트는 요청을 각기 다른 제한 장치에 보내게 될 수 있음
    - 제한 장치끼리 동기화되지 않는다면 클라이언트가 요청해도 처리율 제한을 올바르게 수행할 수 없을 것
    
    → 한 가지 해결책은 고정 세션을 활용하여 같은 클라이언트로부터의 요청은 항상 같은 처리율 제한 장치로 보낼 수 있도록 하는 것(규모면에서 확장가능하지도 유연하지도 않아서 추천하지는 않음)
