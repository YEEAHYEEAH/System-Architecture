# 사용자 수에 따른 규모 확장성

## 단일 서버

![https://mino-park7.github.io/images/2021/system-design-interview/fig1-1.png](https://mino-park7.github.io/images/2021/system-design-interview/fig1-1.png)

### 💬 **단일 서버란?**

모든 컴포넌트가 단 한 대의 서버에서 실행되는 아키텍처입니다. 단일 서버에서는 웹, 앱, 데이터베이스, 캐시 등이 전부 서버 한 대에서 실행됩니다. 그렇다면 단일 서버에서 사용자의 요청은 어떻게 처리될까요?

### 💬 단일 서버에서의 사용자 요청 처리

1. 사용자는 도메인 이름 (www.naver.com)을 이용하여 웹사이트에 접속을 시도합니다. 이 접속을 위해서는 도메인 이름을 `Domain Name Service, DNS`에 물어봐야 합니다. 내가 www.naver.com에 접속하려고 하는데, 얘의 실제 주소는 어디니?와 같은 질문을 하는 것입니다. 이때 DNS는 도메인 이름에 맞는 IP 주소를 찾아 사용자에게 반환해 줍니다.
2. 사용자는 DNS로부터 얻은 IP 주소에 HTTP 요청을 전달합니다. 실제 웹 서버에 자신의 요청을 넣는 과정입니다.
3. 요청을 받은 웹 서버는 사용자에게 HTML 페이지나 JSON 형태로 응답을 반환해 줍니다.

## 데이터베이스

![https://mino-park7.github.io/images/2021/system-design-interview/fig1-3.png](https://mino-park7.github.io/images/2021/system-design-interview/fig1-3.png)

### 💬 데이터베이스 추가하기

사용자가 늘어난다면 서버 하나로는 감당이 버거울 수 있습니다. 따라서 하나의 서버는 웹이나 트래픽을 처리하도록 하고, 하나의 서버는 데이터베이스를 관리하도록 하면 독립적으로 확장이 가능해집니다.

### 💬 어떤 데이터베이스를 사용할 것인가?

❕**관계형 데이터베이스**

관계형 데이터베이스는 `Relational Database Management System, RDBMS`라고도 부릅니다. MySQL,  오라클 PostgreSQL 등이 있습니다. 관계형 데이터베이스는 자료를 열과 칼럼으로 표현하며, SQL을 사용해서 여러 테이블에 있는 데이터를 JOIN하여 합칠 수 있습니다.

❕**비관계형 데이터베이스**

비관계형 데이터베이스는 `NoSQL`이라고도 부릅니다. Redis, Neo4j, HBase 등이 있습니다. NoSQL은 다시 네 부류로 나눌 수 있으며, 그 분류는 다음과 같습니다. 

1. Key-Value 저장소
2. Graph 저장소
3. Column 저장소
4. Document 저장소

또한 비관계형 데이터베이스는 일반적으로 조인 연산을 지원하지 않습니다.

❕**언제나 관계형 데이터베이스? NO!**

많은 개발자들이 관계형 데이터베이스를 선택하고 있습니다. 오랫동안 사용해 온 기술이고 익숙하기 떄문입니다. 하지만 내가 어떤 시스템을 구축할 것이냐에 따라 관계형 데이터베이스가 부적합할 때도 있습니다. 관계형 데이터베이스가 언제나 정답인 것은 아닙니다. 아래는 대표적으로 비관계형 데이터베이스가 바람직한 경우입니다.

1. 아주 낮은 응답 지연 시간이 요구될 때
2. 다루는 데이터가 비정형이라 관계형 데이터가 아닐 때
3. 아주 많은 양의 데이터를 저장해야 할 때

## 수직적 규모 확장 VS 수평적 규모 확장

### 💬 수직적 규모 확장 VS 수평적 규모 확장

❕**수직적 규모 확장 (Scale Up)**

수직적 규모 확장은 서버의 사양을 높이는 것입니다. 즉 다시 말해서 더 좋은 컴퓨터를 사는 것이죠. 서버로 유입되는 트래픽 양이 적을 때는 나쁘지 않은 선택일 수 있습니다. 또한 이 방법의 가장 좋은 점은 규모 확장 방법이 간단하다는 것입니다. 하지만 수직적 규모 확장에는 다음과 같은 단점이 있습니다.

1. 좋은 성능의 컴퓨터는 한계점을 가집니다. 무한대의 성능인 컴퓨터는 존재하지 않기 때문입니다.
2. 장애에 대한 자동 복구 방안이나 다중화 방안을 제시하지 않습니다. 만약 고성능의 서버에서 장애가 발생한다면 모든 서비스가 중단됩니다.

❕**수평적 규모 확장 (Scale Down)**

이에 대한 대응책으로 등장한 것이 수평적 확장입니다. 대부분의 대규모 애플리케이션에서는 수평적 규모 확장 방법을 채택해 사용하고 있습니다. 수평적 규모 확장은 서버의 개수를 늘리는 방법입니다.

### 💬 로드밸런서

![https://mino-park7.github.io/images/2021/system-design-interview/fig1-4.png](https://mino-park7.github.io/images/2021/system-design-interview/fig1-4.png)

로드밸런서는 부하 분산 집합에 속한 웹 서버들에게 트래픽 부하를 고르게 분산하는 역할을 합니다. 그렇다면 로드밸런서가 어떻게 동작하는지 볼까요?

1. 사용자는 로드밸런서가 공개적으로 오픈한 IP 주소에 접속합니다. 따라서 웹 서버는 클라이언트의 요청을 직접 받지 않고, 로드밸런서를 거친 다음 받게 됩니다.
2. 서버들끼리는 보안을 위해 사설 IP 주소를 이용합니다. 사설 IP 주소는 같은 네트워크에 속한 서버 사이의 통신에서만 쓰일 수 있는 주소로, 인터넷을 통해서는 접속할 수 없습니다.

로드밸런서를 사용하게 되면 서버가 다운되었을 때, 아직 남아 있는 멀쩡한 서버로 요청을 위임하여 장애를 대응할 수 있습니다. 또한 웹사이트로 유입되는 트래픽이 가파르게 증가하면 로드밸런서가 우아하게 요청을 분배하여 서버에 보내 줍니다.

### 💬 데이터베이스 다중화

![https://jonghoonpark.com/assets/images/2023-05-01-%EC%82%AC%EC%9A%A9%EC%9E%90-%EC%88%98%EC%97%90-%EB%94%B0%EB%A5%B8-%EA%B7%9C%EB%AA%A8-%ED%99%95%EC%9E%A5%EC%84%B1-2/image1.png](https://jonghoonpark.com/assets/images/2023-05-01-%EC%82%AC%EC%9A%A9%EC%9E%90-%EC%88%98%EC%97%90-%EB%94%B0%EB%A5%B8-%EA%B7%9C%EB%AA%A8-%ED%99%95%EC%9E%A5%EC%84%B1-2/image1.png)

데이터베이스 역시 다중화하여 관리할 수 있습니다. 보통 주 데이터베이스와 부 데이터베이스 관계를 설정하고, 데이터 원본은 주 서버에 저장하고 복사본을 부 서버에 저장하는 방식입니다.

쓰기 연산은 주 서버에서만 지원합니다. 부 서버에서는 그 사본을 전달받고, 읽기 연산을 지원하는 식으로 주 서버를 보조합니다. 이러한 방식으로 데이터베이를 다중화하면 어떤 장점이 있을까요?

1. 쓰기 연산은 주 서버로, 읽기 연산은 부 서버로 나누어서 병렬로 처리될 수 있는 쿼리가 많아지기 때문에 성능이 좋아집니다.
2. 데이터베이스 서버 가운데 일부가 유실되어도 데이터가 보존될 수 있습니다. 즉 안정성이 더욱 높아집니다.
3. 데이터베이스가 여러 지역에 분산되어 있기 때문에 서버 중 일부가 파괴되어도 사용자에게는 서비스 중단 없이 다른 데이터베이스를 통해 서비스할 수 있습니다. 즉 가용성이 좋아집니다.

## 캐시

### 💬 캐시 계층

![https://jonghoonpark.com/assets/images/2023-05-01-%EC%82%AC%EC%9A%A9%EC%9E%90-%EC%88%98%EC%97%90-%EB%94%B0%EB%A5%B8-%EA%B7%9C%EB%AA%A8-%ED%99%95%EC%9E%A5%EC%84%B1-3/image1.png](https://jonghoonpark.com/assets/images/2023-05-01-%EC%82%AC%EC%9A%A9%EC%9E%90-%EC%88%98%EC%97%90-%EB%94%B0%EB%A5%B8-%EA%B7%9C%EB%AA%A8-%ED%99%95%EC%9E%A5%EC%84%B1-3/image1.png)

캐시 계층은 데이터베이스에 자주 접근하는 데이터들을 잠시 보관해 두는 공간입니다. 이러한 캐시 공간을 두면 데이터베이스의 부하를 줄일 수 있고, 자주 읽는 데이터들을 아주 빠르게 불러올 수 있습니다. 사용자의 웹 요청에 대해 캐시에 있는 데이터라면 그냥 읽어 오고, 아니라면 데이터베이스에 접근해서 데이터를 읽어 오는 방식입니다. 이러한 캐시 전략을우선 읽기 전략이라고 합니다. 하지만 캐시는 여러 주의점을 고려해서 사용해야 합니다. 캐시 계층을 두기 전에 어떤 점을 생각해 봐야 할까요?

### 💬 캐시 사용시 주의점

❕**어떤 상황에?**

데이터가 갱신은 자주 일어나지 않지만 읽어오는 작업이 자주 일어나는 경우에 적합합니다.

❕**어떤 데이터를?**

캐시는 데이터를 휘발성 메모리에 두는 구조로, 영구적으로 저장되어야 하는 데이터를 캐시에 두는 것은 바람직하지 않습니다.

**❕어떻게 만료되지?**

만료된 데이터는 캐시에서 삭제해 캐시 메모리를 확보하는 정책 등이 필요합니다. 만료 기간 같은 경우는 너무 짧으면 데이터베이스 접근이 많아져 캐시를 두는 것이 무의미해지고, 너무 길면 데이터베이스와 다른 정보가 저장되어 있을 수 있기 때문에 주의해야 합니다.

**❕장애를 대처하는 방법은?**

캐시 서버를 한 대만 두는 경우 해당 서버가 Single Point of Failure, SPOF가 되어 버릴 가능성이 있습니다. 단일 장애 지점이란 어떤 특정 지점에서의 장애가 전체 시스템의 동작을 중단시켜버릴 가능성이 있는 경우입니다. 따라서 이러한 상황을 피하기 위해서는 여러 지역에 걸쳐 캐시 서버를 분산시키는 것이 좋습니다.

**❕얼마나 크게?**

캐시 메모리가 너무 작은 경우 데이터가 캐시에서 자주 삭제되고, 그만큼 데이터베이스에 자주 접속하여 데이터를 읽어와야 하기 때문에 캐시의 성능이 떨어집니다. 이를 막기 위해서는 캐시 메모리를 여유롭게 잡아야 합니다.

**❕데이터 방출 정책은?**

캐시 메모리가 꽉 차면 새로운 데이터를 받아오기 위해 기존의 데이터는 내보내야 합니다. 기본적으로 Least Recently Used로 가장 오래전에 사용한 데이터를 방출하거나, Least Frequently Used로 사용 빈도가 낮은 데이터를 방출합니다.

## 콘텐츠 전송 네트워크

### 💬 콘텐츠 전송 네트워크

CDN은 정적 콘텐츠를 전송하는 데 쓰이는 지리적으로 분산된 서버의 네트워크입니다. 이미지, 비디오, CSS, JavaScript 파일 등을 캐시할 수 있습니다. 사용자가 어떤 웹 사이트를 방문하면, 그 사용자에게 가장 가까운 CDN 서버가 정적 콘텐츠를 전달하게 됩니다. CDN 서버가 가까이 있으ㅕㅁㄴ 가까이 있을수록 더욱 빠른 로딩 시간을 자랑합니다.

### 💬 CDN 사용 시 고려해야 할 사항

**❕비용**

CDN은 보통 제3 사업자에 의해 운영되고 데이터 전송 양에 따라 비용이 청구되기 때문에 비용에 대한 점을 고려해야 합니다.

**❕적절한 만료 시한 설정**

시의성의 중요한 콘텐츠의 경우 만료 시점을 잘 정해야 합니다. 너무 긴 경우 콘텐츠의 신선도가 떨어지고, 너무 짧은 경우 원본 서버에 빈번하게 접속해야 합니다.

**❕장애 대처 방안**

CDN이 죽었을 경우 원본 서버로부터 직접 콘텐츠를 가져오도록 하는 장애 대처 방안이 마련되어 있어야 합니다.

## 무상태 웹 계층

### 💬 상태 의존적인 아키텍처

![https://jonghoonpark.com/assets/images/2023-05-03-%EC%82%AC%EC%9A%A9%EC%9E%90-%EC%88%98%EC%97%90-%EB%94%B0%EB%A5%B8-%EA%B7%9C%EB%AA%A8-%ED%99%95%EC%9E%A5%EC%84%B1-4/image1.png](https://jonghoonpark.com/assets/images/2023-05-03-%EC%82%AC%EC%9A%A9%EC%9E%90-%EC%88%98%EC%97%90-%EB%94%B0%EB%A5%B8-%EA%B7%9C%EB%AA%A8-%ED%99%95%EC%9E%A5%EC%84%B1-4/image1.png)

웹 계층을 수평적으로 확장하는 방법에 대해 고민해 봅시다. 그러기 위해서는 상태 의존적인 아키텍처에서 벗어나, 무상태 웹 계층을 만들어야 합니다. 위 그림은 서버가 클라이언트의 정보인 상태 정보를 보관하는 상태 정보 의존적인 아키텍처입니다. 이런 식의 아키텍처가 구현되었을 경우, 같은 클라이언트로부터의 요청은 항상 같은 서버로 전송되어야 합니다.

대부분의 로드밸런서가 이를 지원하기 위해 고정 세션이라는 것을 제공하고 있습니다. 하지만 이는 로드밸런서에 부담을 줍니다. 따라서 무상태 아키텍처를 구현하는 쪽을 권장합니다.

### 💬 무상태 아키텍처

![https://jonghoonpark.com/assets/images/2023-05-03-%EC%82%AC%EC%9A%A9%EC%9E%90-%EC%88%98%EC%97%90-%EB%94%B0%EB%A5%B8-%EA%B7%9C%EB%AA%A8-%ED%99%95%EC%9E%A5%EC%84%B1-4/image2.png](https://jonghoonpark.com/assets/images/2023-05-03-%EC%82%AC%EC%9A%A9%EC%9E%90-%EC%88%98%EC%97%90-%EB%94%B0%EB%A5%B8-%EA%B7%9C%EB%AA%A8-%ED%99%95%EC%9E%A5%EC%84%B1-4/image2.png)

이러한 무상태 아키텍처에서 클라이언트는 어떤 웹 서버로든 요청을 전송할 수 있습니다. 웹 서버는 상태 정보가 필요할 경우 공유 저장소로부터 데이터를 가져옵니다. 따라서 상태 정보는 웹 서버로부터 물리적으로 분리되어 있고, 웹 서버가 더는 상태 정보에 의존적이지 않을 수 있습니다.

상태 정보를 저장하는 공유 저장소는 관계형 데이터베이스일 수도 있지만, 일반적으로는 NoSQL을 사용합니다.

## 데이터 센터

![https://jonghoonpark.com/assets/images/2023-05-03-%EC%82%AC%EC%9A%A9%EC%9E%90-%EC%88%98%EC%97%90-%EB%94%B0%EB%A5%B8-%EA%B7%9C%EB%AA%A8-%ED%99%95%EC%9E%A5%EC%84%B1-4/image4.png](https://jonghoonpark.com/assets/images/2023-05-03-%EC%82%AC%EC%9A%A9%EC%9E%90-%EC%88%98%EC%97%90-%EB%94%B0%EB%A5%B8-%EA%B7%9C%EB%AA%A8-%ED%99%95%EC%9E%A5%EC%84%B1-4/image4.png)

위의 그림은 두 개의 데이터 센터를 이용하는 사례입니다. 보통 사용자는 물리적으로 가장 가까운 데이터 센터로 안내되는데, 이것을 지리적 라우팅(geoDNS-routing)이라고 합니다. 위와 같은 아키텍처로 데이터 센터를 여러 개 연결하려면 아래와 같은 기술적 난제들을 해결해야 합니다.

**❕해결해야 하는 문제점**

- 트래픽 우회: 올바른 데이터 센터로 트래픽을 보내는 효과적인 방법을 찾아야 합니다.
- 데이터 동기화: 데이터 센터마다 별도의 데이터베이스를 사용하고 있다면, 장애가 발생했을 때 해당 요청에 트래픽이 다른 데이터센터로 우회되었을 때, 그 데이터베이스에는 데이터가 없는 경우가 발생합니다. 따라서 데이터를 여러 데이터센터에 걸쳐 다중화하는 것이 해결책 중 하나입니다.

## 메시지 큐

![https://jonghoonpark.com/assets/images/2023-05-04-%EC%82%AC%EC%9A%A9%EC%9E%90-%EC%88%98%EC%97%90-%EB%94%B0%EB%A5%B8-%EA%B7%9C%EB%AA%A8-%ED%99%95%EC%9E%A5%EC%84%B1-5/image1.png](https://jonghoonpark.com/assets/images/2023-05-04-%EC%82%AC%EC%9A%A9%EC%9E%90-%EC%88%98%EC%97%90-%EB%94%B0%EB%A5%B8-%EA%B7%9C%EB%AA%A8-%ED%99%95%EC%9E%A5%EC%84%B1-5/image1.png)

메시지 큐란 무엇일까요? 메시지 큐는 데이터의 무손실(Durability), 즉 메시지 큐에 일단 보관된 메시지는 소비자가 꺼낼 때까지 안전히 보관된다는 특성을 보장하는 비동기 통신을 지원하는 컴포넌트입니다. 메시지 큐의 기본 아키텍처는 위 그림과 같습니다. 생산자 또는 발행자라고 불리는 입력 서비스가 메시지를 만들어 메시지 큐에 발행합니다. 큐에는 보통 소비자 혹은 구독자라고 불리는 서버가 연결되어 있는데, 메시지를 받아 그에 맞는 동작을 수행합니다.

메시지 큐를 이용하면 서비스 또는 서버 간 결합이 느슨해져서, 규모 확장성이 보장되는 안정적 애플리케이션을 구성하기 적합합니다.

## 로그, 매트릭 그리고 자동화

### 💬 로그

에러 로그를 모니터링하는 것은 중요합니다. 시스템의 오류와 문제들을 보다 쉽게 찾아낼 수 있도록 하기 때문입니다. 서버 단위에서 로그를 기록할 수도 있지만, 로그만 처리하는 단일 서비스로 빼서 편리하게 관리할 수 있습니다.

### 💬 매트릭

매트릭을 잘 수집하면 비즈니스적으로 유용한 정보를 얻을 수 있습니다. 또한 시스템의 현재 상태를 쉽게 파악할 수도 있습니다. 다음은 매트릭으로부터 알아낼 수 있는 몇몇 유용한 정보들입니다.

- 호스트 단위 매트릭: CPU, 메모리, 디스크와 관련된 매트릭입니다.
- 종합 매트릭: 데이터베이스 계층의 성능, 캐시 계층의 성능 같은 것들이 해당됩니다.
- 핵심 비즈니스 매트릭: 일별 능동 이용자, 수익, 재방문 등이 해당됩니다.

### 💬 자동화

시스템이 커지면 생산성을 높이기 위해 자동화 도구를 활용해야 합니다. CI를 도와주는 파이프라인을 만들어 빌드, 테스트, 배포까지 자동화하면 더욱 편리하게 개발할 수 있습니다.

# 처리율 제한 장치의 설계

## 처리율 제한 장치

![https://mino-park7.github.io/images/2021/system-design-interview/fig1-1.png](https://mino-park7.github.io/images/2021/system-design-interview/fig1-1.png)

### 💬 처리율 제한 장치**란?**

네트워크 시스템에서 처리율 제한 장치는 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치입니다. 아래에 나열된 사례를 보면, 더욱 이해가 쉬울 것입니다.

- 사용자는 초당 2회 이상 새 글을 올릴 수 없다.
- 같은 IP 주소로는 하루에 10개 이상의 계정을 생성할 수 없다.
- 같은 디바이스로는 주당 5회 이상의 리워드를 요청할 수 없다.

API를 처리할 때 이러한 처리율 제한 장치를 왜 두는 것일까요?

1. Dos(Denial of Service) 공격에 의한 자원 고갈을 방지할 수 있습니다.
2. 비용을 절감합니다. 제3자 API에 사용료를 지불하고 있는 회사들에게 특히나 요청에 대한 제한을 걸 수 있어서 급증적인 비용 증감에 대한 안전망으로 사용할 수 있습니다.
3. 서버 과부하를 막습니다.

### 💬 처리율 제한 장치는 어디에 둘 것인가?

이 처리율 제한 장치는 클라이언트 측에 둘 수도 있고, 서버 측에 둘 수도 있습니다. 그러나 클라이언트의 요청은 쉽게 위변조가 가능해 처리율 제한을 안정적으로 수행할 수 있는 장소로는 부적합합니다. 따라서 서버에 두는 방식을 고려해 볼 수 있습니다.

![https://mino-park7.github.io/images/2021/system-design-interview/fig1-1.png](https://mino-park7.github.io/images/2021/system-design-interview/fig1-1.png)

다른 방법을 말해 보자면, 처리율 제한 장치를 API 서버에 두는 대신, 처리율 제한 미들웨어를 만들어서 책임을 분리하는 것입니다.

## 처리율 제한 알고리즘

### 💬 토큰 버킷 알고리즘

[https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcIO7q7%2FbtsBgbjVugB%2Fz17op0f1Kiw4gKHUAVIEFk%2Fimg.png](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcIO7q7%2FbtsBgbjVugB%2Fz17op0f1Kiw4gKHUAVIEFk%2Fimg.png)

토큰 버킷은 지정된 용량을 가지는 컨테이너입니다. 이 버킷에는 사전에 설정된 양의 토큰이 주기적으로 채워집니다. 하나의 요청은 하나의 토큰 컨테이너 위에 올려지게 됩니다. 따라서 요청이 도착했을 때, 사용할 수 있는 토큰이 있는 경우에만 토큰을 꺼내서 사용하고, 그렇지 않을 경우 요청은 버려지게 됩니다. 통상적으로 API 엔드포인트마다 별도의 버킷을 두어서, 기능마다 요청 허용 범위를 다르게 설정합니다.

❕**토큰 버킷 알고리즘 인자**

- 버킷 크기: 버킷에 담을 수 있는 토큰의 최대 개수입니다.
- 토큰 공급률: 초당 몇 개의 토큰이 버킷에 공급되는지입니다.

❕**토큰 버킷 알고리즘 장점**

- 구현이 쉽습니다.
- 메모리 사용 측면에서도 효율적입니다.
- 짧은 시간에 집중되는 트래픽도 처리가 가능합니다.

❕**토큰 버킷 알고리즘 단점**

- 버킷 크기와 토큰 공급률을 적절하게 튜닝하는 것이 어렵습니다.

### 💬 누출 버킷 알고리즘

![https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbj6CQ1%2FbtsBfw9FHb8%2FS9wnYBuAoWHIZGKqBfyGk0%2Fimg.png](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbj6CQ1%2FbtsBfw9FHb8%2FS9wnYBuAoWHIZGKqBfyGk0%2Fimg.png)

누출 버킷 알고리즘은 요청 처리율이 고정되어 있는 알고리즘입니다. 보통 FIFO 큐로 구현합니다. 요청이 도착했을 때 큐가 가득 차 있으면 요청을 버리고, 아니라면 대기 큐에 요청을 추가합니다.

❕**누출 버킷 알고리즘 인자**

- 버킷 크기: 큐 사이즈와 같습니다.
- 처리율: 지정된 시간당 몇 개의 항목을 처리할 것인지입니다.

❕**누출 버킷 알고리즘 장점**

- 큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적입니다.
- 고정된 처리율을 가지고 있기 때문에 안정적인 출력이 필요한 경우에 적합합니다.

❕**누출 버킷 알고리즘 단점**

- 단시간에 많은 트래픽이 몰리는 경우에는 큐에 오래된 요청이 쌓이고, 최신 요청은 버려지게 됩니다.
- 버킷 크기와 처리율을 튜닝하는 것이 어렵습니다.

### 💬 고정 윈도 카운터 알고리즘

![https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FBTtvT%2FbtsBb6Rumc1%2FCyw1gaZXhzixjFrocGxC6K%2Fimg.png](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FBTtvT%2FbtsBb6Rumc1%2FCyw1gaZXhzixjFrocGxC6K%2Fimg.png)

고정 윈도 알고리즘은 타임라인을 고정된 간격의 윈도로 나누고, 각 윈도마다 카운터를 붙입니다. 요청이 접수될 때마다 카운터가 하나씩 증가합니다. 이 카운터가 임게치까지 도달하면 새로운 요청은 새로운 윈도우가 열리는 타임라인이 될 때까지 접수되지 않습니다. 

❕**고정 윈도 버킷 알고리즘 인자**

- 윈도우 사이즈: 타임라인을 나누는 단위입니다.
- 카운터: 한 개의 타임라인에 접수될 수 있는 요청의 개수입니다.

❕**고정 윈도 버킷 알고리즘 장점**

- 메모리 효율이 좋습니다.
- 이해하기 쉽습니다.
- 윈도우가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기에 적합합니다.

❕**고정 윈도 버킷 알고리즘 단점**

- 윈도우 경계 부근에서 일시적으로 많은 트래픽이 몰리는 경우 기대했던 시스템의 처리 한도보다 많은 요청을 접수할 수 있습니다.

### 💬 이중 윈도 로그 알고리즘

이중 윈도 로그 알고리즘은 고정 윈도 카운터의 단점을 해결하기 위한 방안으로, 요청의 타임스탬프를 추적하는 방법입니다. 타임스탬프는 보통 레디스와 같은 캐시에 보관합니다. 새 요청이 오면 만료된 타임스탬프는 제거하고, 새 요청의 타임스탬프를 기록합니다.. 로그의 크기가 허용치보다 같거나 작으면 해당 요청을 시스템에 전달합니다.

❕**이중 윈도 로그 알고리즘 인자**

- 분당 최대 요청 처리 개수: 현재 요청의 타임스탬프 기준으로 분당 몇 개의 요청을 처리할 것인지를 나타냅니다.

❕**이중 윈도 로그 알고리즘 장점**

- 어떤 상황에서도 허용되는 요청의 개수가 시스템 처리율 한도를 초과하지 않습니다.

❕**이중 윈도 로그 알고리즘 단점**

- 거부된 요청의 타임스탬프도 보관하기 때문에 메모리를 많이 사용합니다.

### 💬 이중 윈도 카운터 알고리즘

![https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FwP6Jz%2FbtsBcUjbipT%2FVbBlJmOhLkwnCkpQHlk3g1%2Fimg.png](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FwP6Jz%2FbtsBcUjbipT%2FVbBlJmOhLkwnCkpQHlk3g1%2Fimg.png)

이중 윈도 카운터 알고리즘은 고정 윈도 카운터 알고리즘과 이됭 윈도우 로깅 알고리즘을 결합한 것입니다. 현재 윈도우에 온 요청의 개수를 구하는 공식은 다음과 같습니다.

`현재 1분간의 요청 수 + 직전 1분간의 요청 수 * 이동 윈도우와 직전 윈도우가 겹치는 비율`

❕**이중 윈도 카운터 알고리즘 인자**

- 처리율 제한 장치의 한도: 처리율 제한 장치가 분당 몇 개까지 요청을 처리할 것인지에 대한 값입니다.

❕**이중 윈도 카운터 알고리즘 장점**

- 이전 시간대의 평균 처리율에 따라 현재 윈도우의 상태를 계산하므로 짧은 시간에 몰리는 트래픽에도 잘 대응합니다.
- 메모리 효율이 좋습니다.

❕**이중 윈도 카운터 알고리즘 단점**

- 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하기 때문에 다소 느슨합니다.

## 상세 설계

![https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FHqE5u%2FbtsBcSeBmvG%2FV9YO6sYME1MZX67UKRWAO1%2Fimg.png](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FHqE5u%2FbtsBcSeBmvG%2FV9YO6sYME1MZX67UKRWAO1%2Fimg.png)

### 💬 처리율 제한 규칙

처리율 제한 규칙을 실행하기 위한 카운터의 값들은 보통 빠르게 읽어오기 위해서 레디스와 같은 메모리 기반 저장 장치로 구현합니다. 레디스에서는 두 가지 명령어를 지원합니다.

- `INCR`: 메모리에 지정된 카운터 값을 1만큼 증가시킵니다.
- `EXPIRE`: 카운터에 타임아웃 값을 설정합니다.

그렇다면 처리율 제한 규칙 알고리즘은 어디에 저장되어 있을까요? 보통 설정 파일에 디스크에 저장됩니다.

### 💬 처리율 한도 초과 트래픽의 처리

처리율 한도를 초과한 요청은 그대로 버려질 수도 있고, 메시지 큐에 보관될 수도 있습니다. 그렇다면 클라이언트는 자신의 요청이 처리율 제한에 걸리고 있는지를 어떻게 알 수 있을까요? 그 정답은 HTTP 응답 헤더에 있습니다. 처리율 제한 장치를 설계하면 아래와 같은 HTTP 응답 헤더를 클라이언트에게 전송하게 됩니다.

- `X-Ratelimit-Remaining`: 윈도우 내에 남은 처리 가능한 요청의 개수입니다.
- `X-Ratelimit-Limit`: 매 윈도우마다 클라이언트가 전송할 수 있는 요청의 개수입니다.
- `X-Ratelimit-Retry-After`: 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알려 줍니다.

### 💬 분산 환경에서의 처리율 제한 장치의 구현

분산 환경에서 처리율 제한 장치를 구현하려면 다음과 같은 두 가지 문제를 해결해야 합니다.

**❕경쟁 조건**

요청을 처리하는 여러 개의 스레드가 병렬로 카운터의 값을 증가시킬 경우, 카운터의 값이 제대로 반영되지 않을 수 있습니다. 경쟁 조건을 해결하는 대표적인 해결책은 락을 거는 것이지만, 이는 시스템의 성능을 떨어뜨린다는 문제점을 야기할 수 있습니다.

**❕동기화 이슈**

처리율 제한 장치를 여러 개 두면 동기화가 필요해집니다. 웹 계층은 무상태이므로 클라이언트는 요청을 각기 다른 제한 장치에 보내게 될 수도 있습니다. 제한 장치끼리 동기화되지 않는다면 클라이언트에 대한 카운터 값을 모르기 때문에 처리율 제한이 제대로 이루어지지 않을 수 있습니다. 

이에 대한 해결책 중 하나는 고정 세션을 활용해서 한 클라이언트는 같은 처리율 제한 장치로만 요청을 보내도록 유도하는 것입니다. 하지만 이 방식은 규모면에서 확장 가능하지도 않고, 유연하지도 않기 때문에 추천하지 않습니다. 레디스와 같은 중앙 집중형 저장소를 쓰는 것이 더욱 적합한 방법이라고 볼 수 있겠습니다.
